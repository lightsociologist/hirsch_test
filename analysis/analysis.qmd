---
title: "Hirsch Index Analysis"
format: 
  html:
    code-fold: true
    embed-resources: true
execute:
  warning: false
editor: source
---

```{r}
#| label: timestamp-start
timestamp()
```

```{r}
#| label: setup
#| include: false
library(here)
source(here("check_packages.R"))
load(here("data","data_constructed","analytical_data.RData"))
options(knitr.kable.NA = "")
```

```{r}
#| label: color_palette
#| include: FALSE

# creating color palettes for twenty cases is not easy but lets see if qualpalr
# can help us
pal <- qualpal(20, "pretty_dark")
```

# Between discipline data visualization

```{r}
#| label: fig-scatter_percent_female
#| fig-cap: Scatterplot of mean h-index and percent female across disciplines. Blue line is best fitting line unweighted by discipline sample size. Red line is the same but with nursing excluded.
ggplot(disciplines, aes(x=disc_prop_female, y=disc_h_index))+
  geom_point(aes(size=n_disc, color=field), alpha=0.7)+
  geom_smooth(method="lm", se=FALSE)+
  geom_smooth(data=filter(disciplines, discipline!="Nursing"), color="red",
              method="lm", se=FALSE)+
  geom_text_repel(aes(label=discipline), max.overlaps=6, size=2)+
  scale_x_continuous(labels=scales::percent)+
  scale_color_manual(values=pal$hex)+
  theme_bw()+
  theme(legend.position = "bottom",
        legend.title = element_text(size = 6), 
        legend.text = element_text(size = 4))+
  labs(x="percent female in discipline", y="mean h-index within discipline",
       color="Field")+
  guides(size=FALSE)
```

@fig-scatter_percent_female shows a slightly negative relationship across disciplines between feminization of the discipline and mean h-index. The field of nursing is an outlier, but as the two fitted lines show, it is not an influential point.

```{r}
#| label: fig-scatter-percent_sole
#| fig-cap: Scatterplot of mean h-index and percent sole author across disciplines. Blue line shows best-fitting OLS line unweighted by discipline size.
ggplot(disciplines, aes(x=disc_prop_sole, y=disc_h_index))+
  geom_point(aes(size=n_disc, color=field), alpha=0.7)+
  geom_smooth(method="lm", se=FALSE)+
  geom_text_repel(aes(label=discipline), max.overlaps=6, size=2)+
  scale_x_continuous(labels=scales::percent)+
  scale_color_manual(values=pal$hex)+
  theme_bw()+
  theme(legend.position = "bottom",
        legend.title = element_text(size = 6), 
        legend.text = element_text(size = 4))+
  labs(x="percent sole authored in discipline", y="mean h-index within discipline")+
  guides(size=FALSE)
```

@fig-scatter-percent_sole shows the relationship between sole authorship tendencies in a discipline and mean h-index. Disciplines with more sole authorship have a lower mean h-index and the relationship is quite a strong one. It is also somewhat curvilinear.

# Multilevel models

We now turn to multilevel models to examine both within and between discipline and field effects on h-index values. In the first set of models, we use random intercept models without covariates to partition the variance in the h-index to the individual, discipline, and field levels. We first fit two separate models that partition by discipline and field, respetively and then we do a final model that uses a three level model (individual, discipline, field) to partition the variance in discipline and field simultaneously.

```{r}
#| label: baseline models
model_base_disc <- lmer(h_index ~ 1+(1 | discipline), data=scholars)
model_base_field <- lmer(h_index ~ 1+(1 | field), data=scholars)
model_base_both <- lmer(h_index ~ 1+(1 | discipline)+(1 | discipline:field), 
                        data=scholars)

models_base <- list(model_base_disc, model_base_field, model_base_both)
```

```{r}
#| label: tbl-icc_base
#| tbl-cap: Partitioning of variance in h-index to different levels

# get icc across models in a nice tidy table
map(models_base, function(x) {
              temp <- icc_specs(x) |>
                select(grp, percent)  |>
  mutate(grp=ifelse(grp=="discipline:field", "field", grp),
         grp=factor(grp, levels=c("discipline","field","Residual"),
                    labels=c("Discipline","Field","Individual")))
            }) |>
  reduce(full_join, by="grp") |>
  arrange(grp) |>
  kbl(digits=1, col.names = c("Grouping","Model 1","Model 2","Model 3")) |>
  kable_paper()
```

@tbl-icc_base shows the percentage of the overall variation in h-index scores that can be accounted for at each level. About 68% of the variation in h-indices occurs among individuals in the same discipline, with the remaining third of the variance occurring across disciplines and fields. The results clearly show that fields do not add much beyond the variance at the discipline level. When both levels are considered, disciplinary differences account for about 28% of the variance and fields only for about 4%. 

Based on these results we used a two-level model with only disciplines as the higher level unit for our further substantive analysis. For this analysis, we turned to within-between models to understand the role of two variables both within and between disciplines. These two variables are

* gender, measured by the likelihood that a given name indicates a female gender.
* proportion of publications that are sole-authored.

The basic structure of the within-between models is:

$$y_{ij}=\beta_{0j}+\beta_1(x_{ij}-\bar{x}_j)+\beta_2(\bar{x}_j)+\upsilon_{0j}+\epsilon_{ij}$$

Where $y_{ij}$ is the h-index score of scholar $i$ in discipline $j$. The random intercept $\beta_0j$ is allowed to vary over disciplines. The variable $x$ is the focal variable of interest. It is included at both the individual level (using group mean centering) and at the discipline level, by including its mean at the discipline level. This particular model structure allows us to understand the within discipline effect and between discipline effect of $x$ simultaneously. The $\beta_1$ slope is identical to the slope one would get if they were to instead fit a traditional econometric fixed-effects model (i.e. include dummies for the disciplines), but unlike a traditional fixed-effects model, we can still estimate the between discipline part of the model. The $\beta_2$ slope tells us how much an increase in the mean of the x variable at the disciplinary changes the expected h-index score.

In practice, we include both of our key variables in the model at the same time. We also include a control variable for age which is grand mean centered. The results are shown in the table below.

```{r}
#| label: model-set-up

# Set up models here so they will be consistent in sensitivity analysis

# main effects are group mean centered
formula_disc <- formula(h_index ~ I(prop_female-disc_prop_female)+
  I(100*disc_prop_female)+I(100*(prop_sole-disc_prop_sole))+
  I(100*disc_prop_sole)+(1|discipline))

# add a model with controls for age, specialization and the number of elite 
# scholars per university (all grand mean centered)
formula_controls <- update(formula_disc, .~.+I(age-mean(age))+
                             I(specialization-mean(specialization))+
                             scale(uni_pub_cnt))

# creat coef labels for most complex model
coef_labels <- c("Intercept",
                 "Probability [0-1] of female name (discipline mean centered)",
                 "Discipline mean percent female name",
                 "Percent sole authored publications (discipline mean centered)",
                 "Discipline mean percent sole authored publications",
                 "Age (grand mean centered)",
                 "Specialization [0-1] (grand mean centered)",
                 "Highly productive university count (standardized)")

```

```{r}
#| label: tlb-model_wb
#| tbl-cap: test
#| results: asis
model_wb_disc <- lmer(formula_disc, data=scholars)
model_wb_controls <- lmer(formula_controls, data=scholars)

knitreg(list(model_base_disc, model_wb_disc, model_wb_controls),
        custom.coef.names = coef_labels,
        custom.model.names = c("ANOVA Model","W-B Model","w/controls"),
        caption = "Multilevel models predicting H-index score. Clustering at the disciplinary level.",
        caption.above = TRUE)
```

The results of these models are as follows:

* Within the same discipline, women have h-indexes 2.66 points lower than men, on average. 
* Within the same discipline, a 1% percent increase in sole-authored publication is associated with a 0.46 point reduction in the h-index score.
* Between disciplines, the female concentration of the discipline had little effect on the mean h-index for the discipline. A 1% increase in the percent female is associated with a 0.08 increase in the mean h-index.
* Between disciplines, a 1% increase in the mean percent of sole authored publications is associated witha a 0.49 reduction in the mean h-index. 

So, in summary gender inequity exists within disciplines and inequity by sole authoring tendencies exists both within and between disciplines.

# Sensitivity analysis

## Differences by "Big" Field

@tbl-make-big-fields below shows how we are grouping the specific fields into "big" fields. The only case where we split disciplines across fields is for Economics & Business where we put Economics in the Social Sciences big field and Business in the Professional big field.

```{r}
#| label: tbl-make-big-fields
#| tbl-cap: Check on big field coding
scholars <- scholars %>% 
  mutate(
    big_field = factor(case_when(
      field=="Clinical Medicine" | field=="Biomedical Research" | 
        field=="Public Health & Health Services" ~ "Medical",
      field=="Social Sciences" | field=="Psychology & Cognitive Sciences" | 
        discipline=="Economics" | discipline=="Econometrics" | 
        discipline=="Economic Theory" |
        discipline=="Agricultural Economics & Policy" |
        discipline=="History of Social Sciences" ~ "Social Sciences",
      field=="Physics & Astronomy" | field=="Engineering" | field=="Biology" | 
        field=="Chemistry" | field=="Earth & Environmental Sciences" | 
        field == "Mathematics & Statistics" | 
        field=="Information & Communication Technologies" |
        field== "Agriculture, Fisheries & Forestry" |
        field=="Enabling & Strategic Technologies" ~ "STEM",
      field=="Communication & Textual Studies" | field=="Historical Studies" | 
        field=="Philosophy & Theology" | 
        field=="Visual & Performing Arts" ~ "Humanities",
      field=="Built Environment & Design" | 
        field=="Economics & Business" ~ "Professional"))
  )

scholars %>%
  tabyl(field, big_field) %>%
  gt() %>%
  cols_label(field="Field") %>%
  tab_spanner(label="Big Fields", columns=2:6)
```


We then perform baseline variance partition multilevel models separately for each big field. The results of this partition are shown in @tbl-icc-big-field.

```{r}
#| label: tbl-icc-big-field
#| tbl-cap: Partitioning of variance in h-index to different levels based on models done separately by big field
models_base_big_field <- scholars %>%
  group_by(big_field) %>%
  group_split() %>%
  map(~ lmer(h_index ~ 1+(1 | discipline), data=.x))

map(models_base_big_field, function(x) {
              temp <- icc_specs(x) |>
                select(grp, percent)  |>
  mutate(grp=ifelse(grp=="discipline:field", "field", grp),
         grp=factor(grp, levels=c("discipline","field","Residual"),
                    labels=c("Discipline","Field","Individual")))
            }) |>
  reduce(full_join, by="grp") |>
  arrange(grp) |>
  kbl(digits=1, col.names = c("Grouping", levels(scholars$big_field))) |>
  kable_paper()
```

@tbl-icc-big-field shows some substantial differences across big fields in the degree of partitioning. Most notably, the medical disciplines have the smallest amount of variance at the disciplinary level (only about 16%), while at the other end of the spectrum the humanities have a whopping 52.4% explained at the disciplinary level.

```{r}
#| label: tbl-split-full-models
#| tbl-cap: Multilevel models predicting H-index score, separately by big field.
#| results: asis

models_full_big_field <- scholars %>%
  group_by(big_field) %>%
  group_split() %>%
  map(~ lmer(formula_controls, data=.x))

knitreg(models_full_big_field, 
        caption=NULL,
        custom.coef.names = coef_labels,
        custom.model.names = levels(scholars$big_field),
        caption.above = TRUE)
```
@tbl-split-full-models shows the fullest models from above but this time conducted separately for each big field. The results indicate some substantial heterogeneity in these effects across big fields, although none of the substantial results reverse direction. Some notes on the findings are below:

* In general, the smallest effects were always in the Humanities, with the exception of specialization which was moderately large.
* In general, the largest effects were in the Medical big field, with the exception of specialization effects, which were the smallest of any big field. 
* Specialization had a larger negative effect in the Humanities, Social Sciences, and STEM than Medical and Professional fields.

Overall, our results would not change substantially by focusing on specific big fields. However, it does indicate even greater complexity in trying to understand how to apply h-indexes between large fields of scholarly production.

## Non-linear sole authorship effect

@fig-scatter-percent_sole suggests a non-linear effect of sole authorship. Lets try some non-linearity to see how much this changes our results. First, I will look at some simple transformations on the disciplinary level data.


```{r}
#| label: fig-scatter-sole-nonlinear
#| fig-cap: Scatterplot of mean h-index and percent sole author across disciplines. Blue line shows best-fitting OLS line unweighted by discipline size. The red line shows the best fitting smoothed line via loess. The orange line shows the best fitting parabolic model (i.e. squared term).
ggplot(disciplines, aes(x=disc_prop_sole, y=disc_h_index))+
  geom_point(aes(size=n_disc, color=field), alpha=0.7)+
  geom_smooth(method="lm", se=FALSE)+
  geom_smooth(se=FALSE, color="red")+
  geom_smooth(method="lm", formula=y~x+I(x^2), se=FALSE, color="orange")+
  geom_text_repel(aes(label=discipline), max.overlaps=6, size=2)+
  scale_color_manual(values=pal$hex)+
  scale_x_continuous(labels=scales::percent)+
  theme_bw()+
  theme(legend.position = "bottom",
        legend.title = element_text(size = 6), 
        legend.text = element_text(size = 4))+
  labs(x="percent sole authored in discipline", y="mean h-index within discipline")+
  guides(size=FALSE, color=FALSE)
```

The polynomial approach provide a somewhat better fit than the linear model to most of the distribution, but creates a bit too much curve relative to what the LOESS line is suggesting. Let me try putting the x-axis on a logarithmic scale to see if a logarithmic transformation would be preferable.

```{r}
#| label: fig-scatter-sole-log
#| fig-cap: Scatterplot of mean h-index and percent sole author across disciplines. Blue line shows best-fitting OLS line unweighted by discipline size. The red line shows the best fitting smoothed line via loess. The x-axis is shown on a logarithmic scale.
ggplot(disciplines, aes(x=disc_prop_sole, y=disc_h_index))+
  geom_point(aes(size=n_disc, color=field), alpha=0.7)+
  geom_smooth(method="lm", se=FALSE)+
  geom_smooth(se=FALSE, color="red")+
  geom_text_repel(aes(label=discipline), max.overlaps=6, size=2)+
  scale_x_log10(labels=scales::percent)+
  scale_color_manual(values=pal$hex)+
  theme_bw()+
  theme(legend.position = "bottom",
        legend.title = element_text(size = 6), 
        legend.text = element_text(size = 4))+
  labs(x="percent sole authored in discipline", y="mean h-index within discipline")+
  guides(size=FALSE, color=FALSE)
```

That results fits the data very well. So, I think we should use a log transformation here. 

```{r}
#| label: tlb-model-nlinear
#| tbl-cap: Comparing full model to a model with a log scale on disciplinary mean for proportion sole
#| results: asis

formula_nlinear <- 
  formula(h_index ~ 
            I(prop_female-disc_prop_female)+I(100*disc_prop_female)+
            +I(100*(prop_sole-disc_prop_sole))+log(100*disc_prop_sole)+
            I(age-mean(age))+I(specialization-mean(specialization))+scale(uni_pub_cnt)+
            (1|discipline))

model_wb_nlinear <- lmer(formula_nlinear, data=scholars)

knitreg(list(model_wb_controls, model_wb_nlinear), digits=3,
        custom.coef.names = c(coef_labels, 
                              "Discipline mean percent sole authored pubs (logged)"),
        custom.model.names = c("Original Model","Log Transformed"),
        caption = "Multilevel models predicting H-index score. Clustering at the disciplinary level.",
        caption.above = TRUE)
```

There is no doubt that this is a better fit, with a lower BIC score and an improvement in the discipline-level variance explained. However, its not clear to me that its worth the effort to make this the preferred model for the paper, just due to the complexity of explanation.

```{r}
#| label: timestamp-end
timestamp()
```