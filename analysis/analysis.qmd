---
title: "Hirsch Index Analysis"
format: 
  html:
    toc: true
    code-fold: true
    embed-resources: true
execute:
  warning: false
editor: source
---

```{r}
#| label: timestamp-start
timestamp()
```

```{r}
#| label: setup
#| include: false
library(here)
source(here("check_packages.R"))
load(here("data","data_constructed","analytical_data.RData"))
options(knitr.kable.NA = "")
```

```{r}
#| label: color_palette
#| include: FALSE

# creating color palettes for twenty cases is not easy but lets see if qualpalr
# can help us
pal <- qualpal(20, "pretty_dark")
```

# Between discipline data visualization

```{r}
#| label: fig-scatter_percent_female
#| fig-cap: Scatterplot of mean h-index and percent female across disciplines. Blue line is best fitting line unweighted by discipline sample size. Red line is the same but with nursing excluded.
ggplot(disciplines, aes(x=disc_prop_female, y=disc_h_index))+
  geom_point(aes(size=n_disc, color=field), alpha=0.7)+
  geom_smooth(method="lm", se=FALSE)+
  geom_smooth(data=filter(disciplines, discipline!="Nursing"), color="red",
              method="lm", se=FALSE)+
  geom_text_repel(aes(label=discipline), max.overlaps=6, size=2)+
  scale_x_continuous(labels=scales::percent)+
  scale_color_manual(values=pal$hex)+
  theme_bw()+
  theme(legend.position = "bottom",
        legend.title = element_text(size = 6), 
        legend.text = element_text(size = 4))+
  labs(x="percent female in discipline", y="mean h-index within discipline",
       color="Field")+
  guides(size=FALSE)
```

@fig-scatter_percent_female shows a slightly negative relationship across disciplines between feminization of the discipline and mean h-index. The field of nursing is an outlier, but as the two fitted lines show, it is not an influential point.

```{r}
#| label: fig-scatter-percent_sole
#| fig-cap: Scatterplot of mean h-index and percent sole author across disciplines. Blue line shows best-fitting OLS line unweighted by discipline size. Red line shows best fitting line with percent sole author on the log scale.
ggplot(disciplines, aes(x=disc_prop_sole, y=disc_h_index))+
  geom_point(aes(size=n_disc, color=field), alpha=0.7)+
  geom_smooth(method="lm", se=FALSE)+
  geom_smooth(method="lm", se=FALSE, formula = y ~ log(x), color="red")+
  geom_text_repel(aes(label=discipline), max.overlaps=6, size=2)+
  scale_x_continuous(labels=scales::percent)+
  scale_color_manual(values=pal$hex)+
  theme_bw()+
  theme(legend.position = "bottom",
        legend.title = element_text(size = 6), 
        legend.text = element_text(size = 4))+
  labs(x="percent sole authored in discipline", y="mean h-index within discipline")+
  guides(size=FALSE)
```

@fig-scatter-percent_sole shows the relationship between sole authorship tendencies in a discipline and mean h-index. Disciplines with more sole authorship have a lower mean h-index and the relationship is quite a strong one. It is also clearly curvilinear and fits better when a logarithmic function of the independent variable is used. This is how we will model it.

# Multilevel models

We now turn to multilevel models to examine both within and between discipline and field effects on h-index values. In the first set of models, we use random intercept models without covariates to partition the variance in the h-index to the individual, discipline, and field levels. We first fit two separate models that partition by discipline and field, respectively and then we do a final model that uses a three level model (individual, discipline, field) to partition the variance in discipline and field simultaneously. Because these models do not depend on covariates, we can just use the first of the imputed datasets we created and do not need to pool results as the models will be identical across imputations.

```{r}
#| label: baseline models
model_base_disc <- lmer(h_index ~ 1+(1 | discipline), data=scholars_imp[[1]])
model_base_field <- lmer(h_index ~ 1+(1 | field), data=scholars_imp[[1]])
model_base_both <- lmer(h_index ~ 1+(1 | discipline)+(1 | discipline:field), 
                        data=scholars_imp[[1]])

models_base <- list(model_base_disc, model_base_field, model_base_both)
```

```{r}
#| label: tbl-icc_base
#| tbl-cap: Partitioning of variance in h-index to different levels

# get icc across models in a nice tidy table
map(models_base, function(x) {
              temp <- icc_specs(x) |>
                select(grp, percent)  |>
  mutate(grp=ifelse(grp=="discipline:field", "field", grp),
         grp=factor(grp, levels=c("discipline","field","Residual"),
                    labels=c("Discipline","Field","Individual")))
            }) |>
  reduce(full_join, by="grp") |>
  arrange(grp) |>
  kbl(digits=1, col.names = c("Grouping","Model 1","Model 2","Model 3")) |>
  kable_paper()
```

@tbl-icc_base shows the percentage of the overall variation in h-index scores that can be accounted for at each level. About 68% of the variation in h-indices occurs among individuals in the same discipline, with the remaining third of the variance occurring across disciplines and fields. The results clearly show that fields do not add much beyond the variance at the discipline level. When both levels are considered, disciplinary differences account for about 28% of the variance and fields only for about 4%. 

Based on these results we used a two-level model with only disciplines as the higher level unit for our further substantive analysis. For this analysis, we turned to within-between models to understand the role of two variables both within and between disciplines. These two variables are

* gender, measured by the likelihood that a given name indicates a female gender.
* proportion of publications that are sole-authored.

The basic structure of the within-between models is:

$$y_{ij}=\beta_{0j}+\beta_1(x_{ij}-\bar{x}_j)+\beta_2(\bar{x}_j)+\upsilon_{0j}+\epsilon_{ij}$$

Where $y_{ij}$ is the h-index score of scholar $i$ in discipline $j$. The random intercept $\beta_0j$ is allowed to vary over disciplines. The variable $x$ is the focal variable of interest. It is included at both the individual level (using group mean centering) and at the discipline level, by including its mean at the discipline level. This particular model structure allows us to understand the within discipline effect and between discipline effect of $x$ simultaneously. The $\beta_1$ slope is identical to the slope one would get if they were to instead fit a traditional econometric fixed-effects model (i.e. include dummies for the disciplines), but unlike a traditional fixed-effects model, we can still estimate the between discipline part of the model. The $\beta_2$ slope tells us how much an increase in the mean of the x variable at the disciplinary changes the expected h-index score.

In practice, we include both of our key variables in the model at the same time. We also include a control variable for age which is grand mean centered. The results are shown in the table below.

```{r}
#| label: model-set-up

# Set up models here so they will be consistent in sensitivity analysis

# let do separate prop female and prop sole models because the gender effect
# seems to change
formula_pfemale <- formula(
  h_index ~ I(prop_female-disc_prop_female)+I(100*disc_prop_female)+
    (1|discipline))

formula_psole <- formula(
  h_index ~ I(100*(prop_sole-disc_prop_sole))+log(100*disc_prop_sole)+
    (1|discipline))

# main effects are group mean centered
formula_disc <- formula(
  h_index ~ 
    I(prop_female-disc_prop_female)+I(100*disc_prop_female)+
    +I(100*(prop_sole-disc_prop_sole))+log(100*disc_prop_sole)+
    (1|discipline))

# add a model with controls for age, specialization and the number of elite 
# scholars per university (all grand mean centered)
formula_controls <- update(formula_disc, .~.+I(age-mean(age))+
                             I(specialization-mean(specialization))+
                             scale(uni_pub_cnt))

# creat coef labels for most complex model
coef_labels <- c("Intercept",
                 "Prob. [0-1] of female name (disc. mean ctr.)",
                 "Disc. mean percent female name",
                 "Percent sole authored pubs (disc. mean ctr.)",
                 "Disc. mean percent sole authored pubs (logged)",
                 "Age (grand mean centered)",
                 "Specialization [0-1] (grand mean ctr.)",
                 "Highly productive university count (stdized)")

```

```{r}
#| label: tlb-model_wb
#| tbl-cap: test
#| results: asis
models_wb_pfemale <- map(scholars_imp, ~lmer(formula_pfemale, data=.x))
models_wb_psole <- map(scholars_imp, ~lmer(formula_psole, data=.x))
models_wb_disc <- map(scholars_imp, ~lmer(formula_disc, data=.x))
models_wb_controls <- map(scholars_imp, ~lmer(formula_controls, data=.x))

knitreg(lapply(list(models_wb_pfemale, models_wb_psole, models_wb_disc,
                    models_wb_controls), pool),
        custom.coef.names = coef_labels,
        digits=2,
        #custom.model.names = c("Prop female", "Prop sole","Combined","W/controls"),
        caption = "Multilevel models predicting H-index score. Clustering at the disciplinary level.",
        caption.above = TRUE)
```

The results of these models are as follows:

* Within the same discipline, women have h-indexes 2.64 points lower than men, on average. 
* Within the same discipline, a 1% percent increase in sole-authored publication is associated with a 0.47 point reduction in the h-index score.
* Between disciplines, the female concentration of the discipline had little effect on the mean h-index for the discipline. A 1% increase in the percent female is associated with a 0.08 increase in the mean h-index.
* Between disciplines, a 1% increase (not percentage point, but percent) in the mean percent of sole authored publications is associated witha a 0.135 point reduction in the mean h-index. 
* Controlling for sole authored changes the relationship of the disciplinary feminization (percent female) to the h-index. In the bivariate model, this relationship is negative, but this reverses direction one disciplinary rates of sole authorship are accounted for. This is because heavily feminized disciplines are more likely to be heavily sole-authored disciplines as well (r=`r round(cor(disciplines$disc_prop_female, disciplines$disc_prop_sole), 3)`)

So, in summary gender inequity exists within disciplines and inequity by sole authoring tendencies exists both within and between disciplines.

# Sensitivity analysis

## Differences by "Big" Field

@tbl-make-big-fields below shows how we are grouping the specific fields into "big" fields. The only case where we split disciplines across fields is for Economics & Business where we put Economics in the Social Sciences big field and Business in the Professional big field.

```{r}
#| label: tbl-make-big-fields
#| tbl-cap: Check on big field coding
scholars_imp <- scholars_imp |>
  map(function(x) {
    x <- x |>
      mutate(
        big_field = factor(case_when(
          field=="Clinical Medicine" | field=="Biomedical Research" | 
            field=="Public Health & Health Services" ~ "Medical",
          field=="Social Sciences" | field=="Psychology & Cognitive Sciences" | 
            discipline=="Economics" | discipline=="Econometrics" | 
            discipline=="Economic Theory" |
            discipline=="Agricultural Economics & Policy" |
            discipline=="History of Social Sciences" ~ "Social Sciences",
          field=="Physics & Astronomy" | field=="Engineering" | field=="Biology" | 
            field=="Chemistry" | field=="Earth & Environmental Sciences" | 
            field == "Mathematics & Statistics" | 
            field=="Information & Communication Technologies" |
            field== "Agriculture, Fisheries & Forestry" |
            field=="Enabling & Strategic Technologies" ~ "STEM",
          field=="Communication & Textual Studies" | field=="Historical Studies" | 
            field=="Philosophy & Theology" | 
            field=="Visual & Performing Arts" ~ "Humanities",
          field=="Built Environment & Design" | 
            field=="Economics & Business" ~ "Professional"))
      )
  })
    
scholars_imp[[1]] |>
  tabyl(field, big_field) |>
  gt(rowname_col = "field") |>
  cols_label(field="Field") |>
  tab_spanner(label="Big Fields", columns=2:6) |>
  grand_summary_rows(columns = c(Humanities, Medical, Professional, 
                                 "Social Sciences", STEM), 
                     fns=list(N = ~sum(.)),
                     formatter = fmt_integer)
```

We then perform baseline variance partition multilevel models separately for each big field. The results of this partition are shown in @tbl-icc-big-field.

```{r}
#| label: tbl-icc-big-field
#| tbl-cap: Partitioning of variance in h-index to different levels based on models done separately by big field
models_base_big_field <- scholars_imp[[1]] %>%
  group_by(big_field) %>%
  group_split() %>%
  map(~ lmer(h_index ~ 1+(1 | discipline), data=.x))

map(models_base_big_field, function(x) {
              temp <- icc_specs(x) |>
                select(grp, percent)  |>
  mutate(grp=ifelse(grp=="discipline:field", "field", grp),
         grp=factor(grp, levels=c("discipline","field","Residual"),
                    labels=c("Discipline","Field","Individual")))
            }) |>
  reduce(full_join, by="grp") |>
  arrange(grp) |>
  kbl(digits=1, col.names = c("Grouping", levels(scholars_imp[[1]]$big_field))) |>
  kable_paper()
```

@tbl-icc-big-field shows some substantial differences across big fields in the degree of partitioning. Most notably, the medical disciplines have the smallest amount of variance at the disciplinary level (only about 16%), while at the other end of the spectrum the humanities have a whopping 52.4% explained at the disciplinary level.

```{r}
#| label: tbl-split-full-models
#| tbl-cap: Multilevel models predicting H-index score, separately by big field.
#| results: asis

# this is a bit complex but we need to do it this way to get the lists nested
# in the right way
big_fields <- levels(scholars_imp[[1]]$big_field)
models_full_big_field <- map(big_fields, function(x) {
  models <- map(scholars_imp, function(df) {
    df <- df |>
      filter(big_field==x)
    return(lmer(formula_controls, data=df))
  })
  return(pool(models))
})

knitreg(models_full_big_field, 
        caption=NULL,
        custom.coef.names = coef_labels,
        custom.model.names = big_fields,
        caption.above = TRUE)
```

@tbl-split-full-models shows the fullest models from above but this time conducted separately for each big field. The results indicate some substantial heterogeneity in these effects across big fields, although none of the substantial results reverse direction. Some notes on the findings are below:

* In general, the smallest effects were always in the Humanities, with the exception of specialization which was moderately large.
* In general, the largest effects were in the Medical big field, with the exception of specialization effects, which were the smallest of any big field. 
* Specialization had a larger negative effect in the Humanities, Social Sciences, and STEM than Medical and Professional fields.

Overall, our results would not change substantially by focusing on specific big fields. However, it does indicate even greater complexity in trying to understand how to apply h-indexes between large fields of scholarly production.

```{r}
#| label: timestamp-end
timestamp()
```