---
title: "Organize Hirsch Index Data for Analysis"
format: 
  html:
    toc: true
    code-fold: true
    embed-resources: true
editor: source
---

```{r}
#| label: timestamp-start
timestamp()
```

```{r}
#| label: setup
#| include: false
library(here)
source(here("check_packages.R"))
```

This program incorporates [data](https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw/2) from [Ioannidis et al.](https://www.nature.com/articles/d41586-019-02479-7) to build an analysis of factors related to variation in individual academics' Hirsch scores.

We will use the 2019 data.

```{r}
#| label: read-data
scholars <- read_excel(here("data","data_raw","Table-S6-career-2019.xlsx"), 
                       sheet = "Career")
```

# Individual-level data

The full dataset contains `r format(nrow(scholars), big.mark=",")` entries. We want to reduce the full data in several ways:

* Limit to US scholars.
* Some of the data is a little suspicious, likely due to faulty name disambiguation. We can protect perhaps agaisnt some of that, perhaps, by limiting to recently active scholars and make sure that there is a plausible career here by setting first year to 1960.

```{r}
#| label: filter-data
# total sample size
nrow(scholars)
# count US scholars
sum(scholars$cntry=="usa", na.rm=TRUE)

# restrictions
scholars <- scholars |>
  filter(cntry=="usa" & lastyr>2016 & firstyr>1959)

# final sample size
nrow(scholars)
```

After these reductions, we have `r format(nrow(scholars), big.mark=",")` entries.

Several variables we can get directly or derive easily from the existing dataset:

* `age`: derived from `lastyr-firstyr`.
* `prop_sole`: The proportion of sole authored publications.
* `discipline`: recorded as `sm_subfield_1` in the original data.
* `field`: recorded as `sm_field` in the original data.
* `specialization`: recorded as `sm_field_frac` in the original data.
* `h_index`: The key dependent variable, recorded as `h19` in the original data.

```{r}
#| label: basic-rename-mutate
scholars <- scholars |>
  mutate(age=lastyr-firstyr,
         prop_sole=nps/np6019, 
         discipline=factor(sm_subfield_1),
         field=factor(sm_field)) |>
  rename(h_index=h19, specialization = sm_field_frac)
```

In addition to the variables already included, we want to create two additional variables. The first variable we create is a measure of the number of scholars in the dataset who are also at the focal scholar's institution.

```{r}
#| label: construct-unicount
scholars <- scholars |> 
  group_by(inst_name) |>
  summarize(uni_pub_cnt=n()) |>
  right_join(scholars)
```

Next, we use the [gender](https://cran.r-project.org/web/packages/gender/index.html) package to calculate the probability that a given first name is a female name.
 
```{r}
#| label: add-gender-probs
scholars <- scholars |> 
  mutate(firstname=str_split_fixed(authfull, ",", 2)[,2]) |>
  mutate_at(vars(firstname), function(x){gsub('[^ -~]', '', x)}) |>
  mutate(firstname=str_trim(firstname, side="left"),
         firstname=word(firstname),
         firstname=str_trim(firstname, side="both"))
    
genguess <- gender(scholars$firstname, years=c(1940, 1990), method="ssa")

scholars <- genguess |>
  select(name, proportion_female) |>
  rename(firstname=name, prop_female=proportion_female) |>
  distinct() |>
  right_join(scholars)
```

```{r}
#| label: select-vars
scholars <- scholars |>
  select(h_index, age, prop_female, prop_sole, specialization, uni_pub_cnt, 
         discipline, field)
```

## Summary stats

Now lets do a summary statistics table on our individual level data.

```{r}
#| label: tbl-summary
#| tbl-cap: Descriptive statistics for the individual level data
tbl_summary(scholars, 
            statistic=list(all_continuous() ~ "{mean} {sd}", 
                           all_categorical() ~ "{n} ({p}%)"))
```

## Checking missing values

Lets check missing values on the original data for the variables we have.

```{r}
#| label: tbl-check-missing
#| tbl-cap: Number of missing values on variables in analytical dataseet
sapply(scholars, function(x) {sum(is.na(x))}) %>%
  enframe(name = "Variable", value = "# of missing") %>%
  gt() %>%
  fmt_number(2, decimals=0)
```

We are missing almost 10K gender cases and a few cases for discipline, field, and specialization. The small number of missing cases on discipline, field, and specialization I think can be safely dropped, but dropping the gender cases is a little more questionable. I think we should do imputation on these cases, which will make the dataset a little more complicated to work with, but is do-able. We will use the `mice` package to do multiple imputation via predictive mean matching only on the `prop_female` variable.

```{r}
#| label: multiple-imputation
#| output: false
# the method argument depends on hard coded placements which is annoyting. Lets
# make sure we can alway correctly id the prop_female variable
mice_method <- ifelse(colnames(scholars)=="prop_female", "pmm", "")
scholars.imp <- mice(scholars, 5, method=mice_method)
```

# Aggregating to discipline and field

Now we aggregate mean values of our variables up to the disciplinary and field level. We will merge these values to individual cases for the multilevel models. We also keep disciplinary and field datasets by themselves for some useful data visualizations.

We will create disciplinary and field data from the original data with missing data present.

```{r}
#| label: aggregate-disc-field
#| output: FALSE

# now lets add in discipline and field cluster means for prop_female and prop_sole
disciplines <- scholars |>
  group_by(discipline) |>
  summarize(disc_prop_female=mean(prop_female, na.rm=TRUE),
            disc_prop_sole=mean(prop_sole),
            disc_uni_pub_cnt=mean(uni_pub_cnt),
            disc_age=mean(age),
            disc_specialization=mean(specialization),
            n_disc=n())

fields <- scholars |>
  group_by(field) |>
  summarize(field_prop_female=mean(prop_female, na.rm=TRUE),
            field_prop_sole=mean(prop_sole),
            n_field=n())

# lets also put in mean h_index by discipline and add back in field information
# for fun visualizations
disciplines <- scholars |>
  group_by(discipline) |>
  summarize(disc_h_index=mean(h_index),
            field=unique(field)[1]) |>
  right_join(disciplines) %>%
  left_join(fields)
```

Now we need to do this same thing for each of our imputed datasets so that we can add the discipline and field level variables to each dataset for the analysis. At the same time, I am going to convert the `mids` object which is a pain to work with into simple a simple list of `tibbles`. I will also drop the few remaining missing values in the datasets from other variables.

```{r}
#| label: organize-imputed-data

# first lets put the imputations in a list

scholars_imp <- vector("list",scholars.imp$m)
for(i in 1:scholars.imp$m) {
  scholars_imp[[i]] <- tibble(complete(scholars.imp, i))
}

# now we can use lapply to organize them
scholars_imp <- scholars_imp |>
  map(function(x) {
    disciplines_imp <- x |>
      group_by(discipline) |>
      summarize(disc_prop_female=mean(prop_female),
                disc_prop_sole=mean(prop_sole),
                disc_uni_pub_cnt=mean(uni_pub_cnt),
                disc_age=mean(age),
                disc_specialization=mean(specialization),
                n_disc=n())
    
    fields_imp <- x |>
      group_by(field) |>
      summarize(field_prop_female=mean(prop_female),
                field_prop_sole=mean(prop_sole),
                n_field=n())
    
    # now merge it back together and drop missing cases
    x <- x |>
      left_join(disciplines_imp) |>
      left_join(fields_imp) |>
      drop_na()
    
    return(x)
  })
```

The final sample size of the imputed dataset is `r format(nrow(scholars_imp[[1]]), big.mark=",")`. We dropped `r nrow(scholars)-nrow(scholars_imp[[1]])` cases altogether.

## Disciplinary and field summary stats

We provide some disciplinary and field descriptive statistics for the non-imputed data.

```{r}
#| label: tbl-discipline-stats
#| tbl-cap: Discipline specific statistics. Disciplines are sorted from highest h-index to lowest.
temp <- disciplines |>
  select(discipline, field, n_disc, disc_h_index, disc_prop_female, 
         disc_prop_sole) |>
  mutate(disc_prop_female=100*round(disc_prop_female, 3),
         disc_prop_sole=100*round(disc_prop_sole, 3)) |>
  arrange(desc(disc_h_index))

temp |>
  kbl(col.names=c("Discipline","Field","N","Mean h-index", "% female", 
                  "% sole")) |>
  kable_paper() |>
  column_spec(2, color = "white",
              background = spec_color(as.numeric(temp$field)))
```

```{r}
#| label: tbl-field-stats
#| tbl-cap: Field specific statistics. Fields are sorted from largest to smallest field.
fields |>
  select(field, n_field, field_prop_female, field_prop_sole) |>
  mutate(field_prop_female=100*round(field_prop_female, 3),
         field_prop_sole=100*round(field_prop_sole, 3)) |>
  arrange(desc(n_field))|>
  kbl(col.names=c("Field","N", "% female", "% sole")) |>
  kable_paper() 
```

# Create big fields

@tbl-make-big-fields below shows how we are grouping the specific fields into "big" fields. The only case where we split disciplines across fields is for Economics & Business where we put Economics in the Social Sciences big field and Business in the Professional big field.

```{r}
#| label: tbl-make-big-fields
#| tbl-cap: Check on big field coding
scholars_imp <- scholars_imp |>
  map(function(x) {
    x <- x |>
      mutate(
        big_field = factor(case_when(
          field=="Clinical Medicine" | field=="Biomedical Research" | 
            field=="Public Health & Health Services" ~ "Medical",
          field=="Social Sciences" | field=="Psychology & Cognitive Sciences" | 
            discipline=="Economics" | discipline=="Econometrics" | 
            discipline=="Economic Theory" |
            discipline=="Agricultural Economics & Policy" |
            discipline=="History of Social Sciences" ~ "Social Sciences",
          field=="Physics & Astronomy" | field=="Engineering" | field=="Biology" | 
            field=="Chemistry" | field=="Earth & Environmental Sciences" | 
            field == "Mathematics & Statistics" | 
            field=="Information & Communication Technologies" |
            field== "Agriculture, Fisheries & Forestry" |
            field=="Enabling & Strategic Technologies" ~ "STEM",
          field=="Communication & Textual Studies" | field=="Historical Studies" | 
            field=="Philosophy & Theology" | 
            field=="Visual & Performing Arts" ~ "Humanities",
          field=="Built Environment & Design" | 
            field=="Economics & Business" ~ "Professional"))
      )
  })
    
scholars_imp[[1]] |>
  tabyl(field, big_field) |>
  gt(rowname_col = "field") |>
  cols_label(field="Field") |>
  tab_spanner(label="Big Fields", columns=2:6) |>
  grand_summary_rows(columns = c(Humanities, Medical, Professional, 
                                 "Social Sciences", STEM), 
                     fns=list(N = ~sum(.)),
                     formatter = fmt_integer)
```

# Save the final data

```{r}
#| label: save-analytical-data
save(scholars_imp, disciplines, fields, 
     file=here("data","data_constructed","analytical_data.RData"))
```

```{r}
#| label: timestamp-end
timestamp()
```
